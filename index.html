
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Dental Note Assistant (Vertex AI)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f8fafc; /* slate-50 */
        }
        .transition-all { transition: all 0.3s ease-in-out; }
        .step-inactive { display: none; }
        .step-active { display: flex; flex-direction: column; align-items: center; }
        .pulse-purple { animation: pulse-purple 2s infinite; }
        @keyframes pulse-purple {
            0%, 100% { box-shadow: 0 0 0 0 rgba(168, 85, 247, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(168, 85, 247, 0); }
        }
        .spinner {
            border: 4px solid rgba(0, 0, 0, 0.1);
            width: 24px;
            height: 24px;
            border-radius: 50%;
            border-left-color: #4f46e5;
            animation: spin 1s ease infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        .tooltip {
            position: absolute;
            display: none;
            background-color: #1f2937; /* gray-800 */
            color: white;
            padding: 8px 12px;
            border-radius: 6px;
            z-index: 10;
            width: max-content;
            max-width: 300px;
            font-size: 0.875rem;
            line-height: 1.25rem;
            box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
        }
        .tooltip-source {
            font-style: italic;
            color: #9ca3af; /* gray-400 */
            border-left: 2px solid #4f46e5; /* indigo-600 */
            padding-left: 8px;
            margin-top: 4px;
        }
        .transcript-line {
            padding: 2px 4px;
            border-radius: 3px;
            transition: background-color 0.3s;
        }
        .transcript-highlight {
            background-color: #fef3c7; /* amber-100 */
            border-radius: 3px;
        }
    </style>
</head>
<body class="text-slate-800">

    <div id="app" class="container mx-auto p-4 md:p-6">

        <header class="mb-6 md:mb-8 text-left">
            <div class="flex items-center gap-3 mb-1">
                 <div class="p-2 bg-slate-200 rounded-lg">
                    <svg class="w-6 h-6 text-slate-600" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 8h10M7 12h4m1 8l-4-4H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-3l-4 4z"></path></svg>
                 </div>
                <h1 class="text-2xl md:text-3xl font-bold text-slate-900">AI Dental Note Assistant (Vertex AI)</h1>
            </div>
            <p class="text-slate-500">A modern assistant to streamline your clinical documentation.</p>
        </header>

        <main class="bg-white rounded-lg shadow-sm border border-slate-200 min-h-[60vh] flex items-center justify-center p-6 md:p-8">

            <div id="step-record" class="step-active w-full">
                <h2 class="text-xl font-semibold mb-2 text-slate-700">Ready to Start</h2>
                <p id="mic-permission-status" class="text-slate-500 mb-8 max-w-md text-center">Requesting microphone access...</p>
                <button id="record-btn" disabled class="relative w-24 h-24 bg-slate-400 text-white rounded-full shadow-md transition-all flex items-center justify-center mx-auto cursor-not-allowed">
                    <div id="record-icon-container">
                        <svg class="w-10 h-10" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8h-1a6 6 0 11-12 0H3a7.001 7.001 0 006 6.93V17H7a1 1 0 100 2h6a1 1 0 100-2h-2v-2.07z" clip-rule="evenodd"></path></svg>
                    </div>
                </button>
                <p id="record-status" class="mt-4 text-base font-medium text-slate-600">Waiting for Permission</p>

                <div class="mt-8 text-center border-t pt-6 w-full max-w-md mx-auto">
                    <label for="template-upload-input" id="template-upload-label" class="cursor-pointer bg-white border border-slate-300 text-slate-700 px-4 py-2 rounded-md hover:bg-slate-100 transition-all font-medium text-sm inline-flex items-center gap-2">
                        <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path></svg>
                        Upload Note Template (Optional)
                    </label>
                    <input type="file" id="template-upload-input" class="hidden" accept=".txt">
                    <p id="template-status" class="text-xs text-slate-500 mt-2"></p>
                    <div class="text-slate-400 text-sm font-semibold my-2">OR</div>
                    <label for="upload-audio-input" id="upload-label" class="cursor-pointer bg-slate-200 text-slate-700 px-4 py-2 rounded-md hover:bg-slate-300 transition-all font-medium text-sm inline-flex items-center gap-2">
                         <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 16v1a3 3 0 003 3h10a3 3 0 003-3v-1m-4-8l-4-4m0 0L8 8m4-4v12"></path></svg>
                        Upload Audio File
                    </label>
                    <input type="file" id="upload-audio-input" class="hidden" accept="audio/*">
                </div>
            </div>

            <div id="step-processing" class="step-inactive w-full max-w-lg">
                <div class="flex items-center justify-center mb-4">
                    <div class="spinner"></div>
                </div>
                <h2 class="text-xl font-semibold mb-2 text-slate-700 text-center">Analyzing Session</h2>
                <p id="processing-status" class="mt-2 text-base font-medium text-slate-600 text-center">Initializing...</p>
            </div>

            <div id="step-review" class="step-inactive !flex-row !items-start w-full">
                <div class="w-full">
                    <div class="flex justify-between items-center mb-4">
                        <h2 class="text-xl font-semibold text-slate-700">Review Generated Note</h2>
                        <button id="start-over-btn" class="bg-slate-200 text-slate-700 px-4 py-2 rounded-md hover:bg-slate-300 transition-all font-medium text-sm">Start New Session</button>
                    </div>
                    <div class="grid grid-cols-1 lg:grid-cols-5 gap-6">
                        <div class="lg:col-span-3 space-y-4">
                            <div>
                                <div class="flex items-center gap-2 mb-1">
                                    <label for="soap-s" class="block text-xs font-semibold text-slate-600 uppercase tracking-wider">Subjective</label>
                                    <div class="info-icon" data-target="subjective">
                                        <svg class="w-4 h-4 text-slate-400 cursor-pointer" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>
                                    </div>
                                </div>
                                <textarea id="soap-s" data-section="subjective" rows="5" class="soap-input w-full p-2.5 bg-slate-50 border border-slate-200 rounded-md focus:ring-2 focus:ring-amber-500 focus:border-amber-500"></textarea>
                            </div>
                            <div>
                                <div class="flex items-center gap-2 mb-1">
                                    <label for="soap-o" class="block text-xs font-semibold text-slate-600 uppercase tracking-wider">Objective</label>
                                    <div class="info-icon" data-target="objective">
                                        <svg class="w-4 h-4 text-slate-400 cursor-pointer" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>
                                    </div>
                                </div>
                                <textarea id="soap-o" data-section="objective" rows="5" class="soap-input w-full p-2.5 bg-slate-50 border border-slate-200 rounded-md focus:ring-2 focus:ring-amber-500 focus:border-amber-500"></textarea>
                            </div>
                            <div>
                                <div class="flex items-center gap-2 mb-1">
                                    <label for="soap-a" class="block text-xs font-semibold text-slate-600 uppercase tracking-wider">Assessment</label>
                                    <div class="info-icon" data-target="assessment">
                                        <svg class="w-4 h-4 text-slate-400 cursor-pointer" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>
                                    </div>
                                </div>
                                <textarea id="soap-a" data-section="assessment" rows="5" class="soap-input w-full p-2.5 bg-slate-50 border border-slate-200 rounded-md focus:ring-2 focus:ring-amber-500 focus:border-amber-500"></textarea>
                            </div>
                            <div>
                                <div class="flex items-center gap-2 mb-1">
                                    <label for="soap-p" class="block text-xs font-semibold text-slate-600 uppercase tracking-wider">Plan</label>
                                    <div class="info-icon" data-target="plan">
                                        <svg class="w-4 h-4 text-slate-400 cursor-pointer" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>
                                    </div>
                                </div>
                                <textarea id="soap-p" data-section="plan" rows="5" class="soap-input w-full p-2.5 bg-slate-50 border border-slate-200 rounded-md focus:ring-2 focus:ring-amber-500 focus:border-amber-500"></textarea>
                            </div>
                             <div class="flex justify-end gap-3 items-center">
                                <span id="copy-success-msg" class="text-amber-600 font-medium text-sm hidden">Note Copied!</span>
                                <button id="copy-note-btn" class="bg-slate-700 text-white px-5 py-2 rounded-md hover:bg-slate-800 transition-all font-semibold focus:outline-none focus:ring-4 focus:ring-slate-300 text-sm">Copy Full Note</button>
                            </div>
                        </div>
                        <div class="lg:col-span-2 bg-slate-50 p-4 rounded-lg border border-slate-200 h-[75vh] flex flex-col">
                            <div class="flex justify-between items-center mb-3">
                                <h3 class="text-base font-semibold text-slate-800">Session Recording</h3>
                                <div id="transcript-download-container"></div>
                            </div>
                            <div id="audio-player-container" class="mb-2"></div>
                            <div id="download-container" class="mb-4"></div>
                            <div class="w-full border-t border-slate-200 my-2"></div>
                            <div id="transcript-container" class="overflow-y-auto flex-grow pr-2 space-y-3">
                                </div>
                        </div>
                    </div>
                </div>
            </div>
        </main>
        <div id="tooltip" class="tooltip"></div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const appState = {
                currentStep: 'record',
                isRecording: false,
                mediaRecorder: null,
                audioChunks: [],
                audioBlob: null,
                transcript: null,
                structuredTranscript: [],
                soapSources: {},
                noteTemplate: null,
            };

            // -----------------------------------------------------------------
            // 🚨 VERTEX AI CONFIGURATION - PLEASE FILL THESE OUT 🚨
            // -----------------------------------------------------------------
            // 1. Get your API Key from the Google Cloud Console.
            //    Ensure the "Vertex AI API" is enabled for your project.
            const GOOGLE_API_KEY = "AIzaSyAJ_4c8bWtj3sUAPz-jvOI9rzoMxxDzmBE";

            // 2. Find your Project ID in the Google Cloud Console dashboard.
            const PROJECT_ID = "gen-lang-client-0435092745";

            // 3. Specify the region for your project (e.g., "us-central1").
            const LOCATION = "us-central1";
            // -----------------------------------------------------------------


            const stepRecordEl = document.getElementById('step-record');
            const stepProcessingEl = document.getElementById('step-processing');
            const stepReviewEl = document.getElementById('step-review');

            const recordBtn = document.getElementById('record-btn');
            const recordStatusEl = document.getElementById('record-status');
            const micPermissionStatusEl = document.getElementById('mic-permission-status');
            const recordIconContainer = document.getElementById('record-icon-container');
            const uploadAudioInput = document.getElementById('upload-audio-input');
            const uploadLabel = document.getElementById('upload-label');
            const templateUploadInput = document.getElementById('template-upload-input');
            const templateStatus = document.getElementById('template-status');

            const processingStatusEl = document.getElementById('processing-status');

            const audioPlayerContainer = document.getElementById('audio-player-container');
            const downloadContainer = document.getElementById('download-container');
            const transcriptContainer = document.getElementById('transcript-container');
            const transcriptDownloadContainer = document.getElementById('transcript-download-container');
            const soapS = document.getElementById('soap-s');
            const soapO = document.getElementById('soap-o');
            const soapA = document.getElementById('soap-a');
            const soapP = document.getElementById('soap-p');
            const tooltip = document.getElementById('tooltip');

            const startOverBtn = document.getElementById('start-over-btn');
            const copyNoteBtn = document.getElementById('copy-note-btn');
            const copySuccessMsg = document.getElementById('copy-success-msg');

            const micIcon = `<svg class="w-10 h-10" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8h-1a6 6 0 11-12 0H3a7.001 7.001 0 006 6.93V17H7a1 1 0 100 2h6a1 1 0 100-2h-2v-2.07z" clip-rule="evenodd"></path></svg>`;
            const stopIcon = `<svg class="w-10 h-10" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M5 3a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2V5a2 2 0 00-2-2H5z"></path></svg>`;

            async function setupMicrophone() {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    appState.mediaRecorder = new MediaRecorder(stream);

                    appState.mediaRecorder.ondataavailable = event => {
                        appState.audioChunks.push(event.data);
                    };

                    appState.mediaRecorder.onstop = () => {
                        appState.audioBlob = new Blob(appState.audioChunks, { type: 'audio/wav' });
                        appState.audioChunks = [];
                        processRecording(appState.audioBlob);
                    };

                    micPermissionStatusEl.textContent = 'Click the microphone to begin the session.';
                    recordStatusEl.textContent = 'Click to Record';
                    recordBtn.disabled = false;
                    recordBtn.classList.remove('bg-slate-400', 'cursor-not-allowed');
                    recordBtn.classList.add('bg-slate-700', 'hover:bg-slate-800');
                    uploadLabel.classList.remove('hidden');

                } catch (err) {
                    console.error("Error accessing microphone:", err);
                    micPermissionStatusEl.textContent = 'Microphone access denied. Please enable it in your browser settings and refresh the page.';
                    micPermissionStatusEl.classList.add('text-red-600');
                    recordStatusEl.textContent = 'Microphone Required';
                }
            }
            setupMicrophone();

            function switchStep(step) {
                appState.currentStep = step;
                [stepRecordEl, stepProcessingEl, stepReviewEl].forEach(el => {
                    el.classList.add('step-inactive');
                    el.classList.remove('step-active');
                });
                document.getElementById(`step-${step}`).classList.remove('step-inactive');
                document.getElementById(`step-${step}`).classList.add('step-active');
            }

            function updateProcessingStatus(message, isError = false) {
                processingStatusEl.textContent = message;
                if (isError) {
                    processingStatusEl.classList.add('text-red-600');
                } else {
                    processingStatusEl.classList.remove('text-red-600');
                }
            }

            function blobToBase64(blob) {
                return new Promise((resolve, reject) => {
                    const reader = new FileReader();
                    reader.onloadend = () => resolve(reader.result.split(',')[1]);
                    reader.onerror = reject;
                    reader.readAsDataURL(blob);
                });
            }

            async function processRecording(audioBlob) {
                switchStep('processing');

                if (GOOGLE_API_KEY === "YOUR_API_KEY_HERE" || PROJECT_ID === "your-gcp-project-id") {
                    updateProcessingStatus('API Key or Project ID is not set. Please update the configuration in the script.', true);
                    setTimeout(() => startOver(), 4000);
                    return;
                }

                try {
                    updateProcessingStatus('Preparing audio...');
                    const audioBase64 = await blobToBase64(audioBlob);

                    // --- VERTEX AI API Endpoint ---
                    const model = 'gemini-1.5-flash-001';
                    const vertexUrl = `https://${LOCATION}-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${model}:generateContent`;


                    updateProcessingStatus('Transcribing with Vertex AI...');

                    const transcribePrompt = `You are a highly accurate audio transcription and analysis system. Your task is to process an audio file of a dental consultation and return a structured transcript.

**CRITICAL INSTRUCTIONS:**
1. The output format MUST be a single, valid JSON array.
2. Each element in the array represents one spoken segment.
3. Each element MUST contain three keys: "speaker", "text", and "timestamp".
4. The "timestamp" value MUST be a number representing the start time of the utterance in seconds from the beginning of the audio. This is the most critical part of the output.

**Example of correct output:**
[
  { "speaker": "Dentist", "text": "Good morning, how can I help?", "timestamp": 1.2 },
  { "speaker": "Patient", "text": "I have a toothache.", "timestamp": 3.5 }
]`;

                    const transcribePayload = {
                        contents: [{
                            parts: [
                                { text: transcribePrompt },
                                { inline_data: { mime_type: audioBlob.type, data: audioBase64 } }
                            ]
                        }],
                        generation_config: { response_mime_type: "application/json" }
                    };

                    const transcribeResponse = await fetch(vertexUrl, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                            'Authorization': `Bearer ${GOOGLE_API_KEY}` // Using API Key as Bearer token for this endpoint
                        },
                        body: JSON.stringify(transcribePayload)
                    });

                    if (!transcribeResponse.ok) {
                        const errorBody = await transcribeResponse.json().catch(() => ({ error: { message: transcribeResponse.statusText } }));
                        let errorMessage = errorBody.error?.message || transcribeResponse.statusText;
                        if (transcribeResponse.status === 403) {
                           errorMessage = "Vertex AI API has not been used in project or it is disabled. Enable it by visiting the Vertex AI API page in the Google Cloud Console.";
                        } else if (transcribeResponse.status === 400) {
                           errorMessage = `Bad Request (${transcribeResponse.status}): ${errorMessage}. Check your Project ID and Region.`;
                        } else {
                           errorMessage = `Transcription failed (${transcribeResponse.status}): ${errorMessage}`;
                        }
                        throw new Error(errorMessage);
                    }
                    const transcribeResult = await transcribeResponse.json();

                    if (!transcribeResult.candidates || transcribeResult.candidates.length === 0) {
                        throw new Error("Transcription returned no content. The audio might be silent or too short.");
                    }
                    appState.structuredTranscript = JSON.parse(transcribeResult.candidates[0].content.parts[0].text);
                    appState.transcript = appState.structuredTranscript.map(line => `${line.speaker}: ${line.text}`).join('\n');


                    updateProcessingStatus('Generating SOAP notes with citations...');

                    let soapPrompt;
                    if (appState.noteTemplate) {
                        soapPrompt = `You are a medical note generation assistant. Your primary task is to extract information from a transcript and structure it into a JSON object.
You have been provided with a user's preferred note-taking template. Use this template as a stylistic guide for the content you generate for the "note" fields. The final output must still be the JSON object.

**User's Note Template (for style reference):**
---
${appState.noteTemplate}
---

**Transcript to Analyze:**
---
${appState.transcript}
---

**Required JSON Output Structure:**
Generate a single, valid JSON object with the following keys. For each key, create a "note" that reflects the style of the user's template and a "source" array with exact quotes from the transcript.
{
  "subjective": { "note": "...", "source": ["..."] },
  "objective": { "note": "...", "source": ["..."] },
  "assessment": { "note": "...", "source": ["..."] },
  "plan": { "note": "...", "source": ["..."] }
}
If a section cannot be determined, provide an empty string for the "note" and an empty array for the "source".`;
                    } else {
                        soapPrompt = `You are a medical note generation assistant. Your task is to analyze a dental consultation transcript and generate a structured clinical SOAP note.
The output MUST be a single, valid JSON object that adheres to the following structure:
{
  "subjective": { "note": "A summary of the patient's reported symptoms and feelings.", "source": ["An array of exact quotes from the transcript supporting the subjective note."] },
  "objective": { "note": "A summary of the dentist's objective findings and observations.", "source": ["An array of exact quotes from the transcript supporting the objective note."] },
  "assessment": { "note": "The dentist's diagnosis or assessment of the situation.", "source": ["An array of exact quotes from the transcript supporting the assessment."] },
  "plan": { "note": "The proposed treatment plan, prescriptions, or follow-up actions.", "source": ["An array of exact quotes from the transcript supporting the plan."] }
}
If a section cannot be determined from the transcript, provide an empty string for the "note" and an empty array for the "source". Do not omit any keys.
Transcript to analyze:
---
${appState.transcript}
---`;
                    }

                    const soapPayload = {
                        contents: [{ parts: [{ text: soapPrompt }] }],
                        generation_config: { response_mime_type: "application/json" }
                    };
                    const soapResponse = await fetch(vertexUrl, {
                        method: 'POST',
                        headers: {
                           'Content-Type': 'application/json',
                           'Authorization': `Bearer ${GOOGLE_API_KEY}`
                        },
                        body: JSON.stringify(soapPayload)
                    });
                     if (!soapResponse.ok) {
                        const errorBody = await soapResponse.json().catch(() => ({ error: { message: soapResponse.statusText } }));
                        const errorMessage = errorBody.error?.message || soapResponse.statusText;
                        throw new Error(`SOAP generation failed (${soapResponse.status}): ${errorMessage}`);
                    }
                    const soapResult = await soapResponse.json();
                    const soapNotes = JSON.parse(soapResult.candidates[0].content.parts[0].text);

                    appState.soapSources = {
                        subjective: soapNotes.subjective?.source || [],
                        objective: soapNotes.objective?.source || [],
                        assessment: soapNotes.assessment?.source || [],
                        plan: soapNotes.plan?.source || [],
                    };

                    populateReviewData(appState.structuredTranscript, soapNotes, audioBlob);
                    switchStep('review');

                } catch (error) {
                    console.error("Processing Error:", error);
                    updateProcessingStatus(`${error.message}`, true);
                    setTimeout(() => startOver(), 6000);
                }
            }

            function formatTimestamp(seconds) {
                if (typeof seconds !== 'number' || isNaN(seconds)) {
                    return '[--:--]';
                }
                const minutes = Math.floor(seconds / 60);
                const remainingSeconds = Math.floor(seconds % 60);
                return `[${String(minutes).padStart(2, '0')}:${String(remainingSeconds).padStart(2, '0')}]`;
            }

            function populateReviewData(structuredTranscript, soapNotes, audioBlob) {
                const audioUrl = URL.createObjectURL(audioBlob);
                audioPlayerContainer.innerHTML = `<audio controls src="${audioUrl}" class="w-full"></audio>`;

                const downloadLink = document.createElement('a');
                downloadLink.href = audioUrl;
                downloadLink.download = `dental-recording-${new Date().toISOString()}.wav`;
                downloadLink.innerHTML = `<button class="w-full text-sm bg-slate-200 text-slate-700 px-4 py-2 rounded-md hover:bg-slate-300 transition-all font-medium flex items-center justify-center gap-2">
                        <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 16v1a3 3 0 003 3h10a3 3 0 003-3v-1m-4-4l-4 4m0 0l-4-4m4 4V4"></path></svg>
                        Download Recording
                    </button>`;
                downloadContainer.innerHTML = '';
                downloadContainer.appendChild(downloadLink);

                const plainTranscript = structuredTranscript.map(line => `${formatTimestamp(line.timestamp)} ${line.speaker}: ${line.text}`).join('\n');
                const transcriptBlob = new Blob([plainTranscript], { type: 'text/plain;charset=utf-8' });
                const transcriptUrl = URL.createObjectURL(transcriptBlob);
                const transcriptDownloadLink = document.createElement('a');
                transcriptDownloadLink.href = transcriptUrl;
                transcriptDownloadLink.download = `dental-transcript-${new Date().toISOString()}.txt`;
                transcriptDownloadLink.innerHTML = `<svg class="w-5 h-5 text-slate-500 hover:text-slate-700 transition-colors" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 16v1a3 3 0 003 3h10a3 3 0 003-3v-1m-4-4l-4 4m0 0l-4-4m4 4V4"></path></svg>`;
                transcriptDownloadLink.title = "Download Transcript (.txt)";
                transcriptDownloadContainer.innerHTML = '';
                transcriptDownloadContainer.appendChild(transcriptDownloadLink);

                transcriptContainer.innerHTML = structuredTranscript.map(line => {
                    const speakerClass = line.speaker.toLowerCase().includes('dentist') ? 'text-slate-700' : 'text-amber-700';
                    const fullText = `${line.speaker}: ${line.text}`;
                    return `<div class="transcript-line" data-text="${fullText}">
                        <p class="font-semibold text-sm ${speakerClass}">
                            <span class="text-slate-400 font-mono text-xs">${formatTimestamp(line.timestamp)}</span>
                            ${line.speaker}
                        </p>
                        <p class="text-slate-600 text-sm pl-12">${line.text}</p>
                    </div>`;
                }).join('');

                soapS.value = soapNotes.subjective?.note || "Could not generate.";
                soapO.value = soapNotes.objective?.note || "Could not generate.";
                soapA.value = soapNotes.assessment?.note || "Could not generate.";
                soapP.value = soapNotes.plan?.note || "Could not generate.";
            }

            function startOver() {
                appState.isRecording = false;
                appState.audioBlob = null;
                appState.transcript = null;
                appState.structuredTranscript = [];
                appState.soapSources = {};
                appState.noteTemplate = null;
                audioPlayerContainer.innerHTML = '';
                downloadContainer.innerHTML = '';
                transcriptContainer.innerHTML = '';
                transcriptDownloadContainer.innerHTML = '';
                uploadAudioInput.value = '';
                templateUploadInput.value = '';
                templateStatus.textContent = '';

                recordStatusEl.textContent = 'Click to Record';
                recordBtn.classList.remove('bg-purple-500', 'hover:bg-purple-600', 'pulse-purple');
                recordBtn.classList.add('bg-slate-700', 'hover:bg-slate-800');
                recordIconContainer.innerHTML = micIcon;
                recordBtn.disabled = false;
                uploadLabel.classList.remove('hidden');
                updateProcessingStatus('Initializing...');
                switchStep('record');
            }

            recordBtn.addEventListener('click', () => {
                if (!appState.mediaRecorder) return;

                appState.isRecording = !appState.isRecording;
                if (appState.isRecording) {
                    appState.mediaRecorder.start();
                    recordStatusEl.textContent = 'Recording...';
                    recordBtn.classList.add('bg-purple-500', 'hover:bg-purple-600', 'pulse-purple');
                    recordBtn.classList.remove('bg-slate-700', 'hover:bg-slate-800');
                    recordIconContainer.innerHTML = stopIcon;
                    uploadLabel.classList.add('hidden');
                } else {
                    appState.mediaRecorder.stop();
                    recordStatusEl.textContent = 'Processing...';
                    recordBtn.disabled = true;
                }
            });

            uploadAudioInput.addEventListener('change', (event) => {
                const file = event.target.files[0];
                if (file) {
                    recordBtn.disabled = true;
                    uploadLabel.classList.add('hidden');
                    processRecording(file);
                }
            });

            templateUploadInput.addEventListener('change', (event) => {
                const file = event.target.files[0];
                if (file) {
                    const reader = new FileReader();
                    reader.onload = (e) => {
                        appState.noteTemplate = e.target.result;
                        templateStatus.textContent = `Template "${file.name}" loaded.`;
                        templateStatus.classList.add('text-green-600');
                    };
                    reader.readAsText(file);
                }
            });

            startOverBtn.addEventListener('click', startOver);

            copyNoteBtn.addEventListener('click', () => {
                const fullNote = `Subjective:\n${soapS.value}\n\nObjective:\n${soapO.value}\n\nAssessment:\n${soapA.value}\n\nPlan:\n${soapP.value}\n\n---\n\nFull Transcript:\n${appState.transcript || 'N/A'}`;

                const dummyTextArea = document.createElement('textarea');
                dummyTextArea.value = fullNote;
                document.body.appendChild(dummyTextArea);
                dummyTextArea.select();
                try {
                    document.execCommand('copy');
                    copySuccessMsg.classList.remove('hidden');
                    setTimeout(() => copySuccessMsg.classList.add('hidden'), 2000);
                } catch (err) {
                    console.error('Failed to copy text: ', err);
                }
                document.body.removeChild(dummyTextArea);
            });

            document.querySelectorAll('.info-icon').forEach(icon => {
                icon.addEventListener('mouseenter', (e) => {
                    const target = e.currentTarget.dataset.target;
                    const sources = appState.soapSources[target];
                    if (sources && sources.length > 0) {
                        tooltip.innerHTML = '<strong>Source from transcript:</strong>' + sources.map(s => `<div class="tooltip-source">"${s}"</div>`).join('');
                        tooltip.style.display = 'block';
                        const rect = e.currentTarget.getBoundingClientRect();
                        tooltip.style.left = `${rect.right + 10}px`;
                        tooltip.style.top = `${rect.top}px`;
                    }
                });
                icon.addEventListener('mouseleave', () => {
                    tooltip.style.display = 'none';
                });
            });

            document.querySelectorAll('.soap-input').forEach(input => {
                input.addEventListener('focus', (e) => {
                    const section = e.currentTarget.dataset.section;
                    const sources = appState.soapSources[section];

                    document.querySelectorAll('.transcript-line').forEach(line => {
                        line.classList.remove('transcript-highlight');
                        const lineText = line.dataset.text;
                        if (sources && sources.some(source => lineText.includes(source))) {
                            line.classList.add('transcript-highlight');
                        }
                    });
                });
            });

        });
    </script>
</body>
</html>
