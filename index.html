<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Dental Note Assistant</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <!-- Chosen Palette: Modern Slate & Amber -->
    <!-- Application Structure Plan: A task-oriented, multi-step single-page application that guides the user through a linear workflow: 1) Record Audio, 2) Analyze Conversation, and 3) Review & Finalize Note. This structure was chosen because it mirrors the natural, real-world process a clinician follows, making the application intuitive and easy to use. The UI will dynamically transition between these three states, presenting only the relevant information and actions for each step, which minimizes cognitive load and prevents user error. -->
    <!-- Visualization & Content Choices: 
        - Report Info: Conversation Transcript -> Goal: Organize/Inform -> Viz/Method: A styled list presenting diarized (speaker-labeled) text in a dedicated, scrollable panel. -> Interaction: Scrollable display. -> Justification: This is the most direct and universally understood way to present a conversation log, making it easy for the dentist to reference during review.
        - Report Info: Generated Clinical Note (SOAP) -> Goal: Inform/Organize -> Viz/Method: Four distinct, labeled textarea elements within a form for Subjective, Objective, Assessment, and Plan. -> Interaction: The dentist can directly edit the AI-generated text in each section. -> Justification: Separating the SOAP note into its constituent parts makes it scannable and simplifies editing, which is critical for the human-in-the-loop validation process.
        - Report Info: Application Status -> Goal: Inform -> Viz/Method: Dynamic text indicators, progress bars, and icon changes (e.g., a "recording" icon). -> Interaction: Automatic updates based on application state. -> Justification: Provides clear, immediate feedback to the user on the system's current process (e.g., "Recording...", "Analyzing...", "Ready for Review"), which builds trust and clarifies what is happening.
        - Library/Method: All interactions and dynamic content are handled with vanilla JavaScript, manipulating the DOM. No external visualization libraries are needed for this phase.
    -->
    <!-- CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->
    <style>
        body { 
            font-family: 'Inter', sans-serif; 
            background-color: #f8fafc; /* slate-50 */
        }
        .transition-all { transition: all 0.3s ease-in-out; }
        .step-inactive { display: none; }
        .step-active { display: flex; flex-direction: column; align-items: center; }
        .pulse-purple { animation: pulse-purple 2s infinite; }
        @keyframes pulse-purple {
            0%, 100% { box-shadow: 0 0 0 0 rgba(168, 85, 247, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(168, 85, 247, 0); }
        }
        .spinner {
            border: 4px solid rgba(0, 0, 0, 0.1);
            width: 24px;
            height: 24px;
            border-radius: 50%;
            border-left-color: #4f46e5;
            animation: spin 1s ease infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        .tooltip {
            position: absolute;
            display: none;
            background-color: #1f2937; /* gray-800 */
            color: white;
            padding: 8px 12px;
            border-radius: 6px;
            z-index: 10;
            width: max-content;
            max-width: 300px;
            font-size: 0.875rem;
            line-height: 1.25rem;
            box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
        }
        .tooltip-source {
            font-style: italic;
            color: #9ca3af; /* gray-400 */
            border-left: 2px solid #4f46e5; /* indigo-600 */
            padding-left: 8px;
            margin-top: 4px;
        }
        .transcript-line {
            padding: 2px 4px;
            border-radius: 3px;
            transition: background-color 0.3s;
        }
        .transcript-highlight {
            background-color: #fef3c7; /* amber-100 */
            border-radius: 3px;
        }
    </style>
</head>
<body class="text-slate-800">

    <div id="app" class="container mx-auto p-4 md:p-6">

        <!-- Header -->
        <header class="mb-6 md:mb-8 text-left">
            <div class="flex items-center gap-3 mb-1">
                 <div class="p-2 bg-slate-200 rounded-lg">
                    <svg class="w-6 h-6 text-slate-600" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 8h10M7 12h4m1 8l-4-4H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-3l-4 4z"></path></svg>
                 </div>
                <h1 class="text-2xl md:text-3xl font-bold text-slate-900">AI Dental Note Assistant</h1>
            </div>
            <p class="text-slate-500">A modern assistant to streamline your clinical documentation.</p>
        </header>

        <!-- Main Content Area -->
        <main class="bg-white rounded-lg shadow-sm border border-slate-200 min-h-[60vh] flex items-center justify-center p-6 md:p-8">

            <!-- Step 1: Record Audio -->
            <div id="step-record" class="step-active w-full">
                <h2 class="text-xl font-semibold mb-2 text-slate-700">Ready to Start</h2>
                <p id="mic-permission-status" class="text-slate-500 mb-8 max-w-md text-center">Requesting microphone access...</p>
                <button id="record-btn" disabled class="relative w-24 h-24 bg-slate-400 text-white rounded-full shadow-md transition-all flex items-center justify-center mx-auto cursor-not-allowed">
                    <div id="record-icon-container">
                        <svg class="w-10 h-10" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8h-1a6 6 0 11-12 0H3a7.001 7.001 0 006 6.93V17H7a1 1 0 100 2h6a1 1 0 100-2h-2v-2.07z" clip-rule="evenodd"></path></svg>
                    </div>
                </button>
                <p id="record-status" class="mt-4 text-base font-medium text-slate-600">Waiting for Permission</p>
                
                <div class="mt-8 text-center">
                    <div class="text-slate-400 text-sm font-semibold mb-2">OR</div>
                    <label for="upload-audio-input" id="upload-label" class="cursor-pointer bg-slate-200 text-slate-700 px-4 py-2 rounded-md hover:bg-slate-300 transition-all font-medium text-sm inline-flex items-center gap-2">
                         <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 16v1a3 3 0 003 3h10a3 3 0 003-3v-1m-4-8l-4-4m0 0L8 8m4-4v12"></path></svg>
                        Upload Audio File
                    </label>
                    <input type="file" id="upload-audio-input" class="hidden" accept="audio/*">
                </div>
            </div>

            <!-- Step 2: Processing -->
            <div id="step-processing" class="step-inactive w-full max-w-lg">
                <div class="flex items-center justify-center mb-4">
                    <div class="spinner"></div>
                </div>
                <h2 class="text-xl font-semibold mb-2 text-slate-700 text-center">Analyzing Session</h2>
                <p id="processing-status" class="mt-2 text-base font-medium text-slate-600 text-center">Initializing...</p>
            </div>

            <!-- Step 3: Review Note -->
            <div id="step-review" class="step-inactive !flex-row !items-start w-full">
                <div class="w-full">
                    <div class="flex justify-between items-center mb-4">
                        <h2 class="text-xl font-semibold text-slate-700">Review Generated Note</h2>
                        <button id="start-over-btn" class="bg-slate-200 text-slate-700 px-4 py-2 rounded-md hover:bg-slate-300 transition-all font-medium text-sm">Start New Session</button>
                    </div>
                    <div class="grid grid-cols-1 lg:grid-cols-5 gap-6">
                        <!-- Left: SOAP Note -->
                        <div class="lg:col-span-3 space-y-4">
                            <div>
                                <div class="flex items-center gap-2 mb-1">
                                    <label for="soap-s" class="block text-xs font-semibold text-slate-600 uppercase tracking-wider">Subjective</label>
                                    <div class="info-icon" data-target="subjective">
                                        <svg class="w-4 h-4 text-slate-400 cursor-pointer" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>
                                    </div>
                                </div>
                                <textarea id="soap-s" data-section="subjective" rows="5" class="soap-input w-full p-2.5 bg-slate-50 border border-slate-200 rounded-md focus:ring-2 focus:ring-amber-500 focus:border-amber-500"></textarea>
                            </div>
                            <div>
                                <div class="flex items-center gap-2 mb-1">
                                    <label for="soap-o" class="block text-xs font-semibold text-slate-600 uppercase tracking-wider">Objective</label>
                                    <div class="info-icon" data-target="objective">
                                        <svg class="w-4 h-4 text-slate-400 cursor-pointer" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>
                                    </div>
                                </div>
                                <textarea id="soap-o" data-section="objective" rows="5" class="soap-input w-full p-2.5 bg-slate-50 border border-slate-200 rounded-md focus:ring-2 focus:ring-amber-500 focus:border-amber-500"></textarea>
                            </div>
                            <div>
                                <div class="flex items-center gap-2 mb-1">
                                    <label for="soap-a" class="block text-xs font-semibold text-slate-600 uppercase tracking-wider">Assessment</label>
                                    <div class="info-icon" data-target="assessment">
                                        <svg class="w-4 h-4 text-slate-400 cursor-pointer" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>
                                    </div>
                                </div>
                                <textarea id="soap-a" data-section="assessment" rows="5" class="soap-input w-full p-2.5 bg-slate-50 border border-slate-200 rounded-md focus:ring-2 focus:ring-amber-500 focus:border-amber-500"></textarea>
                            </div>
                            <div>
                                <div class="flex items-center gap-2 mb-1">
                                    <label for="soap-p" class="block text-xs font-semibold text-slate-600 uppercase tracking-wider">Plan</label>
                                    <div class="info-icon" data-target="plan">
                                        <svg class="w-4 h-4 text-slate-400 cursor-pointer" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>
                                    </div>
                                </div>
                                <textarea id="soap-p" data-section="plan" rows="5" class="soap-input w-full p-2.5 bg-slate-50 border border-slate-200 rounded-md focus:ring-2 focus:ring-amber-500 focus:border-amber-500"></textarea>
                            </div>
                             <div class="flex justify-end gap-3 items-center">
                                <span id="copy-success-msg" class="text-amber-600 font-medium text-sm hidden">Note Copied!</span>
                                <button id="copy-note-btn" class="bg-slate-700 text-white px-5 py-2 rounded-md hover:bg-slate-800 transition-all font-semibold focus:outline-none focus:ring-4 focus:ring-slate-300 text-sm">Copy Full Note</button>
                            </div>
                        </div>
                        <!-- Right: Transcript & Audio Player -->
                        <div class="lg:col-span-2 bg-slate-50 p-4 rounded-lg border border-slate-200 h-[75vh] flex flex-col">
                            <div class="flex justify-between items-center mb-3">
                                <h3 class="text-base font-semibold text-slate-800">Session Recording</h3>
                                <div id="transcript-download-container"></div>
                            </div>
                            <div id="audio-player-container" class="mb-2"></div>
                            <div id="download-container" class="mb-4"></div>
                            <div class="w-full border-t border-slate-200 my-2"></div>
                            <div id="transcript-container" class="overflow-y-auto flex-grow pr-2 space-y-3">
                                <!-- Transcript will be injected here -->
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </main>
        <div id="tooltip" class="tooltip"></div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const appState = {
                currentStep: 'record',
                isRecording: false,
                mediaRecorder: null,
                audioChunks: [],
                audioBlob: null,
                transcript: null,
                soapSources: {},
            };

            // -----------------------------------------------------------------
            // HARDCODE YOUR API KEY HERE
            // -----------------------------------------------------------------
            const GEMINI_API_KEY = "AIzaSyAJ_4c8bWtj3sUAPz-jvOI9rzoMxxDzmBE"; 
            // -----------------------------------------------------------------

            const stepRecordEl = document.getElementById('step-record');
            const stepProcessingEl = document.getElementById('step-processing');
            const stepReviewEl = document.getElementById('step-review');
            
            const recordBtn = document.getElementById('record-btn');
            const recordStatusEl = document.getElementById('record-status');
            const micPermissionStatusEl = document.getElementById('mic-permission-status');
            const recordIconContainer = document.getElementById('record-icon-container');
            const uploadAudioInput = document.getElementById('upload-audio-input');
            const uploadLabel = document.getElementById('upload-label');

            const processingStatusEl = document.getElementById('processing-status');

            const audioPlayerContainer = document.getElementById('audio-player-container');
            const downloadContainer = document.getElementById('download-container');
            const transcriptContainer = document.getElementById('transcript-container');
            const transcriptDownloadContainer = document.getElementById('transcript-download-container');
            const soapS = document.getElementById('soap-s');
            const soapO = document.getElementById('soap-o');
            const soapA = document.getElementById('soap-a');
            const soapP = document.getElementById('soap-p');
            const tooltip = document.getElementById('tooltip');

            const startOverBtn = document.getElementById('start-over-btn');
            const copyNoteBtn = document.getElementById('copy-note-btn');
            const copySuccessMsg = document.getElementById('copy-success-msg');

            const micIcon = `<svg class="w-10 h-10" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8h-1a6 6 0 11-12 0H3a7.001 7.001 0 006 6.93V17H7a1 1 0 100 2h6a1 1 0 100-2h-2v-2.07z" clip-rule="evenodd"></path></svg>`;
            const stopIcon = `<svg class="w-10 h-10" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M5 3a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2V5a2 2 0 00-2-2H5z"></path></svg>`;

            async function setupMicrophone() {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    appState.mediaRecorder = new MediaRecorder(stream);

                    appState.mediaRecorder.ondataavailable = event => {
                        appState.audioChunks.push(event.data);
                    };

                    appState.mediaRecorder.onstop = () => {
                        appState.audioBlob = new Blob(appState.audioChunks, { type: 'audio/wav' });
                        appState.audioChunks = [];
                        processRecording(appState.audioBlob);
                    };
                    
                    micPermissionStatusEl.textContent = 'Click the microphone to begin the session.';
                    recordStatusEl.textContent = 'Click to Record';
                    recordBtn.disabled = false;
                    recordBtn.classList.remove('bg-slate-400', 'cursor-not-allowed');
                    recordBtn.classList.add('bg-slate-700', 'hover:bg-slate-800');
                    uploadLabel.classList.remove('hidden');

                } catch (err) {
                    console.error("Error accessing microphone:", err);
                    micPermissionStatusEl.textContent = 'Microphone access denied. Please enable it in your browser settings and refresh the page.';
                    micPermissionStatusEl.classList.add('text-red-600');
                    recordStatusEl.textContent = 'Microphone Required';
                }
            }
            setupMicrophone();

            function switchStep(step) {
                appState.currentStep = step;
                [stepRecordEl, stepProcessingEl, stepReviewEl].forEach(el => {
                    el.classList.add('step-inactive');
                    el.classList.remove('step-active');
                });
                document.getElementById(`step-${step}`).classList.remove('step-inactive');
                document.getElementById(`step-${step}`).classList.add('step-active');
            }

            function updateProcessingStatus(message, isError = false) {
                processingStatusEl.textContent = message;
                if (isError) {
                    processingStatusEl.classList.add('text-red-600');
                } else {
                    processingStatusEl.classList.remove('text-red-600');
                }
            }
            
            function blobToBase64(blob) {
                return new Promise((resolve, reject) => {
                    const reader = new FileReader();
                    reader.onloadend = () => resolve(reader.result.split(',')[1]);
                    reader.onerror = reject;
                    reader.readAsDataURL(blob);
                });
            }

            async function processRecording(audioBlob) {
                switchStep('processing');
                
                if (GEMINI_API_KEY === "YOUR_API_KEY_HERE") {
                    updateProcessingStatus('API Key is not set. Please hardcode your key in the script.', true);
                    setTimeout(() => startOver(), 4000);
                    return;
                }
                
                try {
                    updateProcessingStatus('Preparing audio...');
                    const audioBase64 = await blobToBase64(audioBlob);
                    
                    updateProcessingStatus('Transcribing with AI...');
                    const transcribeUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GEMINI_API_KEY}`;
                    const transcribePayload = {
                        contents: [{
                            parts: [
                                { text: "Transcribe this audio of a dental consultation. Identify the speakers as 'Dentist' and 'Patient'." },
                                { inlineData: { mimeType: audioBlob.type, data: audioBase64 } }
                            ]
                        }]
                    };
                    const transcribeResponse = await fetch(transcribeUrl, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(transcribePayload)
                    });
                    
                    if (!transcribeResponse.ok) {
                        const errorBody = await transcribeResponse.json().catch(() => ({ error: { message: transcribeResponse.statusText } }));
                        let errorMessage = errorBody.error?.message || transcribeResponse.statusText;
                        if (transcribeResponse.status === 400 && errorMessage.includes("API key not valid")) {
                           errorMessage = "API Key not valid. Please check the key and ensure the Generative Language API is enabled in your Google Cloud project.";
                        } else {
                           errorMessage = `Transcription failed (${transcribeResponse.status}): ${errorMessage}`;
                        }
                        throw new Error(errorMessage);
                    }
                    const transcribeResult = await transcribeResponse.json();
                    
                    if (!transcribeResult.candidates || transcribeResult.candidates.length === 0) {
                        throw new Error("Transcription returned no content. The audio might be silent or too short.");
                    }
                    appState.transcript = transcribeResult.candidates[0].content.parts[0].text;

                    updateProcessingStatus('Generating SOAP notes with citations...');
                    const soapPrompt = `You are a medical note generation assistant. Your task is to analyze a dental consultation transcript and generate a structured clinical SOAP note.

The output MUST be a single, valid JSON object that adheres to the following structure:
{
  "subjective": {
    "note": "A summary of the patient's reported symptoms and feelings.",
    "source": ["An array of exact quotes from the transcript supporting the subjective note."]
  },
  "objective": {
    "note": "A summary of the dentist's objective findings and observations.",
    "source": ["An array of exact quotes from the transcript supporting the objective note."]
  },
  "assessment": {
    "note": "The dentist's diagnosis or assessment of the situation.",
    "source": ["An array of exact quotes from the transcript supporting the assessment."]
  },
  "plan": {
    "note": "The proposed treatment plan, prescriptions, or follow-up actions.",
    "source": ["An array of exact quotes from the transcript supporting the plan."]
  }
}

If a section cannot be determined from the transcript, provide an empty string for the "note" and an empty array for the "source". Do not omit any keys.

Here is the transcript to analyze:
---
${appState.transcript}
---`;
                    
                    const soapPayload = {
                        contents: [{ parts: [{ text: soapPrompt }] }],
                        generationConfig: { responseMimeType: "application/json" }
                    };
                    const soapResponse = await fetch(transcribeUrl, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(soapPayload)
                    });
                     if (!soapResponse.ok) {
                        const errorBody = await soapResponse.json().catch(() => ({ error: { message: soapResponse.statusText } }));
                        const errorMessage = errorBody.error?.message || soapResponse.statusText;
                        throw new Error(`SOAP generation failed (${soapResponse.status}): ${errorMessage}`);
                    }
                    const soapResult = await soapResponse.json();
                    const soapNotes = JSON.parse(soapResult.candidates[0].content.parts[0].text);
                    
                    appState.soapSources = {
                        subjective: soapNotes.subjective?.source || [],
                        objective: soapNotes.objective?.source || [],
                        assessment: soapNotes.assessment?.source || [],
                        plan: soapNotes.plan?.source || [],
                    };

                    populateReviewData(appState.transcript, soapNotes, audioBlob);
                    switchStep('review');

                } catch (error) {
                    console.error("Processing Error:", error);
                    updateProcessingStatus(`${error.message}`, true);
                    setTimeout(() => startOver(), 6000);
                }
            }

            function populateReviewData(transcript, soapNotes, audioBlob) {
                const audioUrl = URL.createObjectURL(audioBlob);
                audioPlayerContainer.innerHTML = `<audio controls src="${audioUrl}" class="w-full"></audio>`;

                const downloadLink = document.createElement('a');
                downloadLink.href = audioUrl;
                downloadLink.download = `dental-recording-${new Date().toISOString()}.wav`;
                downloadLink.innerHTML = `<button class="w-full text-sm bg-slate-200 text-slate-700 px-4 py-2 rounded-md hover:bg-slate-300 transition-all font-medium flex items-center justify-center gap-2">
                        <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 16v1a3 3 0 003 3h10a3 3 0 003-3v-1m-4-4l-4 4m0 0l-4-4m4 4V4"></path></svg>
                        Download Recording
                    </button>`;
                downloadContainer.innerHTML = '';
                downloadContainer.appendChild(downloadLink);

                const transcriptBlob = new Blob([transcript], { type: 'text/plain;charset=utf-8' });
                const transcriptUrl = URL.createObjectURL(transcriptBlob);
                const transcriptDownloadLink = document.createElement('a');
                transcriptDownloadLink.href = transcriptUrl;
                transcriptDownloadLink.download = `dental-transcript-${new Date().toISOString()}.txt`;
                transcriptDownloadLink.innerHTML = `<svg class="w-5 h-5 text-slate-500 hover:text-slate-700 transition-colors" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 16v1a3 3 0 003 3h10a3 3 0 003-3v-1m-4-4l-4 4m0 0l-4-4m4 4V4"></path></svg>`;
                transcriptDownloadLink.title = "Download Transcript (.txt)";
                transcriptDownloadContainer.innerHTML = '';
                transcriptDownloadContainer.appendChild(transcriptDownloadLink);

                transcriptContainer.innerHTML = transcript.split('\n').map(line => {
                    if (!line.includes(':')) return `<div class="transcript-line"><p class="text-slate-600 text-sm">${line}</p></div>`;
                    const [speaker, ...textParts] = line.split(':');
                    const text = textParts.join(':').trim();
                    const speakerClass = speaker.toLowerCase().includes('dentist') ? 'text-slate-700' : 'text-amber-700';
                    return `<div class="transcript-line">
                        <p class="font-semibold text-sm ${speakerClass}">${speaker}</p>
                        <p class="text-slate-600 text-sm">${text}</p>
                    </div>`;
                }).join('');

                soapS.value = soapNotes.subjective?.note || "Could not generate.";
                soapO.value = soapNotes.objective?.note || "Could not generate.";
                soapA.value = soapNotes.assessment?.note || "Could not generate.";
                soapP.value = soapNotes.plan?.note || "Could not generate.";
            }
            
            function startOver() {
                appState.isRecording = false;
                appState.audioBlob = null;
                appState.transcript = null;
                appState.soapSources = {};
                audioPlayerContainer.innerHTML = '';
                downloadContainer.innerHTML = '';
                transcriptContainer.innerHTML = '';
                transcriptDownloadContainer.innerHTML = '';
                uploadAudioInput.value = ''; // Reset file input
                
                recordStatusEl.textContent = 'Click to Record';
                recordBtn.classList.remove('bg-purple-500', 'hover:bg-purple-600', 'pulse-purple');
                recordBtn.classList.add('bg-slate-700', 'hover:bg-slate-800');
                recordIconContainer.innerHTML = micIcon;
                recordBtn.disabled = false;
                uploadLabel.classList.remove('hidden');
                updateProcessingStatus('Initializing...');
                switchStep('record');
            }

            recordBtn.addEventListener('click', () => {
                if (!appState.mediaRecorder) return;
                
                appState.isRecording = !appState.isRecording;
                if (appState.isRecording) {
                    appState.mediaRecorder.start();
                    recordStatusEl.textContent = 'Recording...';
                    recordBtn.classList.add('bg-purple-500', 'hover:bg-purple-600', 'pulse-purple');
                    recordBtn.classList.remove('bg-slate-700', 'hover:bg-slate-800');
                    recordIconContainer.innerHTML = stopIcon;
                    uploadLabel.classList.add('hidden');
                } else {
                    appState.mediaRecorder.stop();
                    recordStatusEl.textContent = 'Processing...';
                    recordBtn.disabled = true;
                }
            });

            uploadAudioInput.addEventListener('change', (event) => {
                const file = event.target.files[0];
                if (file) {
                    recordBtn.disabled = true;
                    uploadLabel.classList.add('hidden');
                    processRecording(file);
                }
            });

            startOverBtn.addEventListener('click', startOver);
            
            copyNoteBtn.addEventListener('click', () => {
                const fullNote = `Subjective:\n${soapS.value}\n\nObjective:\n${soapO.value}\n\nAssessment:\n${soapA.value}\n\nPlan:\n${soapP.value}\n\n---\n\nFull Transcript:\n${appState.transcript || 'N/A'}`;
                
                const dummyTextArea = document.createElement('textarea');
                dummyTextArea.value = fullNote;
                document.body.appendChild(dummyTextArea);
                dummyTextArea.select();
                try {
                    document.execCommand('copy');
                    copySuccessMsg.classList.remove('hidden');
                    setTimeout(() => copySuccessMsg.classList.add('hidden'), 2000);
                } catch (err) {
                    console.error('Failed to copy text: ', err);
                }
                document.body.removeChild(dummyTextArea);
            });

            document.querySelectorAll('.info-icon').forEach(icon => {
                icon.addEventListener('mouseenter', (e) => {
                    const target = e.currentTarget.dataset.target;
                    const sources = appState.soapSources[target];
                    if (sources && sources.length > 0) {
                        tooltip.innerHTML = '<strong>Source from transcript:</strong>' + sources.map(s => `<div class="tooltip-source">"${s}"</div>`).join('');
                        tooltip.style.display = 'block';
                        const rect = e.currentTarget.getBoundingClientRect();
                        tooltip.style.left = `${rect.right + 10}px`;
                        tooltip.style.top = `${rect.top}px`;
                    }
                });
                icon.addEventListener('mouseleave', () => {
                    tooltip.style.display = 'none';
                });
            });

            document.querySelectorAll('.soap-input').forEach(input => {
                input.addEventListener('focus', (e) => {
                    const section = e.currentTarget.dataset.section;
                    const sources = appState.soapSources[section];
                    
                    document.querySelectorAll('.transcript-line').forEach(line => {
                        line.classList.remove('transcript-highlight');
                        const lineText = line.innerText || line.textContent;
                        if (sources && sources.some(source => lineText.includes(source))) {
                            line.classList.add('transcript-highlight');
                        }
                    });
                });
            });

        });
    </script>
</body>
</html>
